{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "This file contains the model training using the data that was formatted in the `data_format.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model\n",
    "For this project, I used ResNet-like model which uses 3 dimension (height, width, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a base class for each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(dimension, dimension, 3, padding='same')\n",
    "        self.conv2 = nn.Conv3d(dimension, dimension, 3, padding='same')\n",
    "        self.norm1 = nn.BatchNorm3d(dimension)\n",
    "        self.norm2 = nn.BatchNorm3d(dimension)\n",
    "        self.act = nn.GELU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        x = x + identity\n",
    "\n",
    "        x = self.act(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempResNet(nn.Module):\n",
    "    def __init__(self, channel, depth):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.encode = nn.Conv3d(channel, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
    "        self.norm = nn.BatchNorm3d(64)\n",
    "        self.expand1 = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, 1),\n",
    "            nn.BatchNorm3d(128)\n",
    "        )\n",
    "        self.expand2 = nn.Sequential(\n",
    "            nn.Conv3d(128, 256, 1),\n",
    "            nn.BatchNorm3d(256)\n",
    "        )\n",
    "        self.expand3 = nn.Sequential(\n",
    "            nn.Conv3d(256, 512, 1),\n",
    "            nn.BatchNorm3d(512)\n",
    "        )\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "        self.max_pool1 = nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
    "        self.max_pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0)\n",
    "\n",
    "        self.block1 = Block(64)\n",
    "        self.block2 = Block(128)\n",
    "        self.block3 = Block(256)\n",
    "        self.block4 = Block(512)\n",
    "\n",
    "        self.ave_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(512, depth*21*3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.expand1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.expand2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.max_pool2(x)\n",
    "\n",
    "        x = self.expand3(x)\n",
    "        x = self.block4(x)\n",
    "\n",
    "        x = self.ave_pool(x)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        x = x.view(-1, self.depth, 21, 3)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [i for i in range(0, 80, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bone(start, end, ax, c):\n",
    "    xs = [start[0], end[0]]\n",
    "    ys = [start[1], end[1]]\n",
    "    zs = [start[2], end[2]]\n",
    "    ax.plot(xs, ys, zs, color=c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, root='./', transform=None, test=False):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        if test:\n",
    "            self.images = np.load(os.path.join(root, 'data/image_path_test.npy'))\n",
    "            self.movement = np.load(os.path.join(root, 'data/movement_test.npy'))\n",
    "        else:\n",
    "            self.images = np.load(os.path.join(root, 'data/image_path.npy'))\n",
    "            self.movement = np.load(os.path.join(root, 'data/movement.npy'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, points3D, path)\n",
    "        \"\"\"\n",
    "        paths = []\n",
    "        images = []\n",
    "        for img_name in self.images[index]:\n",
    "            path = os.path.join(self.root, img_name)\n",
    "            paths.append(path)\n",
    "            images.append(Image.open(path))\n",
    "        movement = self.movement[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            for i in range(len(images)):\n",
    "                images[i] = self.transform(images[i])\n",
    "        \n",
    "        images = torch.stack(images).permute(1, 0, 2, 3)\n",
    "\n",
    "        return images, movement, paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "train_dataset = Dataset(transform=transform)\n",
    "test_dataset = Dataset(transform=transform, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=16, pin_memory=True)\n",
    "testloader = data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, movement, paths = train_dataset[0]\n",
    "channel, depth, img_size, _ = imgs.shape\n",
    "\n",
    "model = TempResNet(channel, depth).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TempResNet                               [1, 10, 21, 3]            --\n",
       "├─Conv3d: 1-1                            [1, 64, 10, 128, 128]     28,224\n",
       "├─BatchNorm3d: 1-2                       [1, 64, 10, 128, 128]     128\n",
       "├─GELU: 1-3                              [1, 64, 10, 128, 128]     --\n",
       "├─MaxPool3d: 1-4                         [1, 64, 10, 64, 64]       --\n",
       "├─Block: 1-5                             [1, 64, 10, 64, 64]       --\n",
       "│    └─Conv3d: 2-1                       [1, 64, 10, 64, 64]       110,656\n",
       "│    └─BatchNorm3d: 2-2                  [1, 64, 10, 64, 64]       128\n",
       "│    └─GELU: 2-3                         [1, 64, 10, 64, 64]       --\n",
       "│    └─Conv3d: 2-4                       [1, 64, 10, 64, 64]       110,656\n",
       "│    └─BatchNorm3d: 2-5                  [1, 64, 10, 64, 64]       128\n",
       "│    └─GELU: 2-6                         [1, 64, 10, 64, 64]       --\n",
       "├─MaxPool3d: 1-6                         [1, 64, 10, 32, 32]       --\n",
       "├─Sequential: 1-7                        [1, 128, 10, 32, 32]      --\n",
       "│    └─Conv3d: 2-7                       [1, 128, 10, 32, 32]      8,320\n",
       "│    └─BatchNorm3d: 2-8                  [1, 128, 10, 32, 32]      256\n",
       "├─Block: 1-8                             [1, 128, 10, 32, 32]      --\n",
       "│    └─Conv3d: 2-9                       [1, 128, 10, 32, 32]      442,496\n",
       "│    └─BatchNorm3d: 2-10                 [1, 128, 10, 32, 32]      256\n",
       "│    └─GELU: 2-11                        [1, 128, 10, 32, 32]      --\n",
       "│    └─Conv3d: 2-12                      [1, 128, 10, 32, 32]      442,496\n",
       "│    └─BatchNorm3d: 2-13                 [1, 128, 10, 32, 32]      256\n",
       "│    └─GELU: 2-14                        [1, 128, 10, 32, 32]      --\n",
       "├─MaxPool3d: 1-9                         [1, 128, 10, 16, 16]      --\n",
       "├─Sequential: 1-10                       [1, 256, 10, 16, 16]      --\n",
       "│    └─Conv3d: 2-15                      [1, 256, 10, 16, 16]      33,024\n",
       "│    └─BatchNorm3d: 2-16                 [1, 256, 10, 16, 16]      512\n",
       "├─Block: 1-11                            [1, 256, 10, 16, 16]      --\n",
       "│    └─Conv3d: 2-17                      [1, 256, 10, 16, 16]      1,769,728\n",
       "│    └─BatchNorm3d: 2-18                 [1, 256, 10, 16, 16]      512\n",
       "│    └─GELU: 2-19                        [1, 256, 10, 16, 16]      --\n",
       "│    └─Conv3d: 2-20                      [1, 256, 10, 16, 16]      1,769,728\n",
       "│    └─BatchNorm3d: 2-21                 [1, 256, 10, 16, 16]      512\n",
       "│    └─GELU: 2-22                        [1, 256, 10, 16, 16]      --\n",
       "├─MaxPool3d: 1-12                        [1, 256, 10, 8, 8]        --\n",
       "├─Sequential: 1-13                       [1, 512, 10, 8, 8]        --\n",
       "│    └─Conv3d: 2-23                      [1, 512, 10, 8, 8]        131,584\n",
       "│    └─BatchNorm3d: 2-24                 [1, 512, 10, 8, 8]        1,024\n",
       "├─Block: 1-14                            [1, 512, 10, 8, 8]        --\n",
       "│    └─Conv3d: 2-25                      [1, 512, 10, 8, 8]        7,078,400\n",
       "│    └─BatchNorm3d: 2-26                 [1, 512, 10, 8, 8]        1,024\n",
       "│    └─GELU: 2-27                        [1, 512, 10, 8, 8]        --\n",
       "│    └─Conv3d: 2-28                      [1, 512, 10, 8, 8]        7,078,400\n",
       "│    └─BatchNorm3d: 2-29                 [1, 512, 10, 8, 8]        1,024\n",
       "│    └─GELU: 2-30                        [1, 512, 10, 8, 8]        --\n",
       "├─AdaptiveAvgPool3d: 1-15                [1, 512, 1, 1, 1]         --\n",
       "├─Flatten: 1-16                          [1, 512]                  --\n",
       "├─Linear: 1-17                           [1, 630]                  323,190\n",
       "==========================================================================================\n",
       "Total params: 19,332,662\n",
       "Trainable params: 19,332,662\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 41.13\n",
       "==========================================================================================\n",
       "Input size (MB): 7.86\n",
       "Forward/backward pass size (MB): 361.76\n",
       "Params size (MB): 77.33\n",
       "Estimated Total Size (MB): 446.96\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model, input_size=(1, channel, depth, img_size, img_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Evaluation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_accuracy(pred, target):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        pred (torch.Tensor): [batch_size, depth, 21, 3]\n",
    "        target (torch.Tensor): [batch_size, depth, 21, 3]\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float): average accuracy\n",
    "    \"\"\"\n",
    "    pred_hand = pred[:, -1, :, :].squeeze(1)\n",
    "    target_hand = target[:, -1, :, :].squeeze(1)\n",
    "\n",
    "    distances = torch.sqrt(torch.sum((pred_hand - target_hand) ** 2, dim=2))\n",
    "\n",
    "    mean_distances = distances.mean(dim=1)\n",
    "\n",
    "    accuracies = [0 for _ in range(len(thresholds))]\n",
    "    for mean_distance in mean_distances:\n",
    "        for i in range(len(thresholds)):\n",
    "            accuracies[i] += 1 if mean_distance <= thresholds[i] else 0\n",
    "    \n",
    "    for i in range(len(accuracies)):\n",
    "        accuracies[i] /= len(mean_distances)\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movement_accuracy(pred, target):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        pred (torch.Tensor): [batch_size, depth, 21, 3]\n",
    "        target (torch.Tensor): [batch_size, depth, 21, 3]\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float): average accuracy\n",
    "    \"\"\"\n",
    "    pred_move = pred[:, -1, [0, 1, 5], :]\n",
    "    target_move = target[:, -1, [0, 1, 5], :]\n",
    "\n",
    "    distances = torch.sqrt(torch.sum((pred_move - target_move) ** 2, dim=2))\n",
    "\n",
    "    mean_distances = distances.mean(dim=1)\n",
    "\n",
    "    accuracies = [0 for _ in range(len(thresholds))]\n",
    "    for mean_distance in mean_distances:\n",
    "        for i in range(len(thresholds)):\n",
    "            accuracies[i] += 1 if mean_distance <= thresholds[i] else 0\n",
    "    \n",
    "    for i in range(len(accuracies)):\n",
    "        accuracies[i] /= len(mean_distances)\n",
    "    \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Train Step and Test Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer):\n",
    "  model.train()\n",
    "\n",
    "  train_loss, train_shape_acc, train_movement_acc = 0, [0 for _ in range(len(thresholds))], [0 for _ in range(len(thresholds))]\n",
    "\n",
    "  for batch, (X, movement, _) in enumerate(dataloader):\n",
    "    X, movement = X.float().to(DEVICE), movement.float().to(DEVICE)\n",
    "\n",
    "    pred_movement = model(X)\n",
    "\n",
    "    loss = loss_fn(pred_movement, movement)\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    shape_accuracies = shape_accuracy(pred_movement, movement)\n",
    "    movement_accuracies = movement_accuracy(pred_movement, movement)\n",
    "\n",
    "    for i in range(len(thresholds)):\n",
    "      train_shape_acc[i] += shape_accuracies[i]\n",
    "      train_movement_acc[i] += movement_accuracies[i]\n",
    "\n",
    "  train_loss /= len(dataloader)\n",
    "  for i in range(len(train_shape_acc)):\n",
    "    train_shape_acc[i] /= len(dataloader)\n",
    "  for i in range(len(train_movement_acc)):\n",
    "    train_movement_acc[i] /= len(dataloader)\n",
    "\n",
    "  return train_loss, train_shape_acc, train_movement_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module):\n",
    "  model.eval()\n",
    "\n",
    "  test_loss, test_shape_acc, test_movement_acc = 0, [0 for _ in range(len(thresholds))], [0 for _ in range(len(thresholds))]\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X, movement, _) in enumerate(dataloader):\n",
    "      X, movement = X.to(DEVICE), movement.to(DEVICE)\n",
    "\n",
    "      pred_movement = model(X)\n",
    "\n",
    "      loss = loss_fn(pred_movement, movement)\n",
    "      test_loss += loss.item()\n",
    "\n",
    "      shape_accuracies = shape_accuracy(pred_movement, movement)\n",
    "      movement_accuracies = movement_accuracy(pred_movement, movement)\n",
    "\n",
    "      for i in range(len(thresholds)):\n",
    "        test_shape_acc[i] += shape_accuracies[i]\n",
    "        test_movement_acc[i] += movement_accuracies[i]\n",
    "\n",
    "  test_loss /= len(dataloader)\n",
    "  for i in range(len(test_shape_acc)):\n",
    "    test_shape_acc[i] /= len(dataloader)\n",
    "  for i in range(len(test_movement_acc)):\n",
    "    test_movement_acc[i] /= len(dataloader)\n",
    "\n",
    "  return test_loss, test_shape_acc, test_movement_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          scheduler: torch.optim.lr_scheduler._LRScheduler=None,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int=5):\n",
    "\n",
    "  results = {\n",
    "      \"train_loss\": [],\n",
    "      \"train_shape_acc\": [],\n",
    "      \"train_movement_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_shape_acc\": [],\n",
    "      \"test_movement_acc\": [],\n",
    "  }\n",
    "\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_shape_acc, train_movement_acc = train_step(model=model, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer)\n",
    "    if scheduler != None:\n",
    "      scheduler.step()\n",
    "    test_loss, test_shape_acc, test_movement_acc = test_step(model, dataloader=test_dataloader, loss_fn=loss_fn)\n",
    "\n",
    "    print(f\"Epoch: {epoch} | Train Loss: {train_loss:.4f} | Train Shape Acc: {train_shape_acc[4]:.3f} | Train Movement Acc: {train_movement_acc[4]:.3f} | Test Loss: {test_loss:.4f} | Test Shape Acc: {test_shape_acc[4]:.3f} | Test Movement Acc: {test_movement_acc[4]:.3f}\")\n",
    "\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_shape_acc\"].append(train_shape_acc)\n",
    "    results[\"train_movement_acc\"].append(train_movement_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_shape_acc\"].append(test_shape_acc)\n",
    "    results[\"test_movement_acc\"].append(test_movement_acc)\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af58b13dab504a9d8b0af728cabd9eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 1251.1442 | Train Shape Acc: 0.110 | Train Movement Acc: 0.059 | Test Loss: 7459.7711 | Test Shape Acc: 0.000 | Test Movement Acc: 0.000\n",
      "Epoch: 1 | Train Loss: 1157.9348 | Train Shape Acc: 0.171 | Train Movement Acc: 0.078 | Test Loss: 1917.7626 | Test Shape Acc: 0.135 | Test Movement Acc: 0.002\n",
      "Epoch: 2 | Train Loss: 1120.6874 | Train Shape Acc: 0.174 | Train Movement Acc: 0.072 | Test Loss: 1906.8619 | Test Shape Acc: 0.074 | Test Movement Acc: 0.000\n",
      "Epoch: 3 | Train Loss: 1083.5413 | Train Shape Acc: 0.204 | Train Movement Acc: 0.088 | Test Loss: 1250.5532 | Test Shape Acc: 0.131 | Test Movement Acc: 0.010\n",
      "Epoch: 4 | Train Loss: 1061.4866 | Train Shape Acc: 0.187 | Train Movement Acc: 0.067 | Test Loss: 2847.3204 | Test Shape Acc: 0.036 | Test Movement Acc: 0.000\n",
      "Epoch: 5 | Train Loss: 1003.7060 | Train Shape Acc: 0.195 | Train Movement Acc: 0.072 | Test Loss: 1480.2115 | Test Shape Acc: 0.104 | Test Movement Acc: 0.008\n",
      "Epoch: 6 | Train Loss: 977.5283 | Train Shape Acc: 0.210 | Train Movement Acc: 0.077 | Test Loss: 958.4294 | Test Shape Acc: 0.073 | Test Movement Acc: 0.025\n",
      "Epoch: 7 | Train Loss: 950.3344 | Train Shape Acc: 0.253 | Train Movement Acc: 0.101 | Test Loss: 923.8420 | Test Shape Acc: 0.070 | Test Movement Acc: 0.016\n",
      "Epoch: 8 | Train Loss: 925.5236 | Train Shape Acc: 0.229 | Train Movement Acc: 0.090 | Test Loss: 10068.4308 | Test Shape Acc: 0.002 | Test Movement Acc: 0.000\n",
      "Epoch: 9 | Train Loss: 881.1344 | Train Shape Acc: 0.234 | Train Movement Acc: 0.101 | Test Loss: 2247.1693 | Test Shape Acc: 0.000 | Test Movement Acc: 0.000\n",
      "Epoch: 10 | Train Loss: 843.3032 | Train Shape Acc: 0.270 | Train Movement Acc: 0.111 | Test Loss: 1116.3752 | Test Shape Acc: 0.097 | Test Movement Acc: 0.012\n",
      "Epoch: 11 | Train Loss: 828.5831 | Train Shape Acc: 0.290 | Train Movement Acc: 0.099 | Test Loss: 2119.3319 | Test Shape Acc: 0.086 | Test Movement Acc: 0.000\n",
      "Epoch: 12 | Train Loss: 815.3211 | Train Shape Acc: 0.281 | Train Movement Acc: 0.106 | Test Loss: 876.3635 | Test Shape Acc: 0.187 | Test Movement Acc: 0.037\n",
      "Epoch: 13 | Train Loss: 755.1138 | Train Shape Acc: 0.291 | Train Movement Acc: 0.124 | Test Loss: 764.5124 | Test Shape Acc: 0.117 | Test Movement Acc: 0.052\n",
      "Epoch: 14 | Train Loss: 727.4316 | Train Shape Acc: 0.315 | Train Movement Acc: 0.124 | Test Loss: 910.4686 | Test Shape Acc: 0.174 | Test Movement Acc: 0.010\n",
      "Epoch: 15 | Train Loss: 707.2154 | Train Shape Acc: 0.327 | Train Movement Acc: 0.133 | Test Loss: 1635.2388 | Test Shape Acc: 0.100 | Test Movement Acc: 0.002\n",
      "Epoch: 16 | Train Loss: 663.6464 | Train Shape Acc: 0.328 | Train Movement Acc: 0.140 | Test Loss: 3566.4500 | Test Shape Acc: 0.047 | Test Movement Acc: 0.002\n",
      "Epoch: 17 | Train Loss: 627.6316 | Train Shape Acc: 0.375 | Train Movement Acc: 0.159 | Test Loss: 3478.6103 | Test Shape Acc: 0.048 | Test Movement Acc: 0.004\n",
      "Epoch: 18 | Train Loss: 602.1602 | Train Shape Acc: 0.411 | Train Movement Acc: 0.171 | Test Loss: 878.8014 | Test Shape Acc: 0.117 | Test Movement Acc: 0.029\n",
      "Epoch: 19 | Train Loss: 583.0903 | Train Shape Acc: 0.421 | Train Movement Acc: 0.194 | Test Loss: 775.0616 | Test Shape Acc: 0.226 | Test Movement Acc: 0.020\n",
      "Epoch: 20 | Train Loss: 586.5846 | Train Shape Acc: 0.380 | Train Movement Acc: 0.167 | Test Loss: 2510.2866 | Test Shape Acc: 0.097 | Test Movement Acc: 0.004\n",
      "Epoch: 21 | Train Loss: 561.7757 | Train Shape Acc: 0.436 | Train Movement Acc: 0.184 | Test Loss: 714.9778 | Test Shape Acc: 0.203 | Test Movement Acc: 0.033\n",
      "Epoch: 22 | Train Loss: 524.5680 | Train Shape Acc: 0.472 | Train Movement Acc: 0.216 | Test Loss: 732.5950 | Test Shape Acc: 0.226 | Test Movement Acc: 0.055\n",
      "Epoch: 23 | Train Loss: 503.2411 | Train Shape Acc: 0.490 | Train Movement Acc: 0.223 | Test Loss: 824.0651 | Test Shape Acc: 0.264 | Test Movement Acc: 0.031\n",
      "Epoch: 24 | Train Loss: 483.0185 | Train Shape Acc: 0.538 | Train Movement Acc: 0.248 | Test Loss: 1218.2552 | Test Shape Acc: 0.209 | Test Movement Acc: 0.030\n",
      "Epoch: 25 | Train Loss: 483.4865 | Train Shape Acc: 0.546 | Train Movement Acc: 0.233 | Test Loss: 915.5258 | Test Shape Acc: 0.201 | Test Movement Acc: 0.032\n",
      "Epoch: 26 | Train Loss: 449.6917 | Train Shape Acc: 0.562 | Train Movement Acc: 0.265 | Test Loss: 1042.9577 | Test Shape Acc: 0.217 | Test Movement Acc: 0.004\n",
      "Epoch: 27 | Train Loss: 438.9100 | Train Shape Acc: 0.557 | Train Movement Acc: 0.272 | Test Loss: 756.2212 | Test Shape Acc: 0.268 | Test Movement Acc: 0.065\n",
      "Epoch: 28 | Train Loss: 425.9141 | Train Shape Acc: 0.577 | Train Movement Acc: 0.271 | Test Loss: 1126.8772 | Test Shape Acc: 0.141 | Test Movement Acc: 0.002\n",
      "Epoch: 29 | Train Loss: 427.1656 | Train Shape Acc: 0.597 | Train Movement Acc: 0.267 | Test Loss: 809.9133 | Test Shape Acc: 0.249 | Test Movement Acc: 0.029\n",
      "Epoch: 30 | Train Loss: 404.8212 | Train Shape Acc: 0.620 | Train Movement Acc: 0.293 | Test Loss: 690.6978 | Test Shape Acc: 0.186 | Test Movement Acc: 0.016\n",
      "Epoch: 31 | Train Loss: 355.6544 | Train Shape Acc: 0.635 | Train Movement Acc: 0.330 | Test Loss: 690.7738 | Test Shape Acc: 0.339 | Test Movement Acc: 0.059\n",
      "Epoch: 32 | Train Loss: 356.0244 | Train Shape Acc: 0.658 | Train Movement Acc: 0.344 | Test Loss: 1687.4033 | Test Shape Acc: 0.155 | Test Movement Acc: 0.013\n",
      "Epoch: 33 | Train Loss: 331.0413 | Train Shape Acc: 0.678 | Train Movement Acc: 0.351 | Test Loss: 1321.0750 | Test Shape Acc: 0.293 | Test Movement Acc: 0.023\n",
      "Epoch: 34 | Train Loss: 344.3431 | Train Shape Acc: 0.686 | Train Movement Acc: 0.355 | Test Loss: 754.7197 | Test Shape Acc: 0.180 | Test Movement Acc: 0.057\n",
      "Epoch: 35 | Train Loss: 335.9576 | Train Shape Acc: 0.671 | Train Movement Acc: 0.340 | Test Loss: 806.4225 | Test Shape Acc: 0.160 | Test Movement Acc: 0.045\n",
      "Epoch: 36 | Train Loss: 304.8567 | Train Shape Acc: 0.703 | Train Movement Acc: 0.390 | Test Loss: 657.3714 | Test Shape Acc: 0.320 | Test Movement Acc: 0.073\n",
      "Epoch: 37 | Train Loss: 305.9765 | Train Shape Acc: 0.686 | Train Movement Acc: 0.379 | Test Loss: 805.7558 | Test Shape Acc: 0.215 | Test Movement Acc: 0.092\n",
      "Epoch: 38 | Train Loss: 259.9140 | Train Shape Acc: 0.758 | Train Movement Acc: 0.457 | Test Loss: 683.0404 | Test Shape Acc: 0.347 | Test Movement Acc: 0.088\n",
      "Epoch: 39 | Train Loss: 248.5046 | Train Shape Acc: 0.729 | Train Movement Acc: 0.458 | Test Loss: 924.4050 | Test Shape Acc: 0.261 | Test Movement Acc: 0.052\n",
      "Epoch: 40 | Train Loss: 197.4200 | Train Shape Acc: 0.814 | Train Movement Acc: 0.573 | Test Loss: 580.2628 | Test Shape Acc: 0.417 | Test Movement Acc: 0.157\n",
      "Epoch: 41 | Train Loss: 161.4661 | Train Shape Acc: 0.837 | Train Movement Acc: 0.670 | Test Loss: 590.3229 | Test Shape Acc: 0.415 | Test Movement Acc: 0.145\n",
      "Epoch: 42 | Train Loss: 157.9360 | Train Shape Acc: 0.833 | Train Movement Acc: 0.673 | Test Loss: 602.1761 | Test Shape Acc: 0.417 | Test Movement Acc: 0.147\n",
      "Epoch: 43 | Train Loss: 152.5693 | Train Shape Acc: 0.845 | Train Movement Acc: 0.681 | Test Loss: 597.9824 | Test Shape Acc: 0.393 | Test Movement Acc: 0.127\n",
      "Epoch: 44 | Train Loss: 149.5340 | Train Shape Acc: 0.844 | Train Movement Acc: 0.701 | Test Loss: 620.9634 | Test Shape Acc: 0.399 | Test Movement Acc: 0.127\n",
      "Epoch: 45 | Train Loss: 146.5787 | Train Shape Acc: 0.853 | Train Movement Acc: 0.693 | Test Loss: 612.0881 | Test Shape Acc: 0.372 | Test Movement Acc: 0.131\n",
      "Epoch: 46 | Train Loss: 139.4500 | Train Shape Acc: 0.854 | Train Movement Acc: 0.731 | Test Loss: 611.8847 | Test Shape Acc: 0.399 | Test Movement Acc: 0.134\n",
      "Epoch: 47 | Train Loss: 132.6414 | Train Shape Acc: 0.858 | Train Movement Acc: 0.746 | Test Loss: 633.1742 | Test Shape Acc: 0.384 | Test Movement Acc: 0.115\n",
      "Epoch: 48 | Train Loss: 141.4459 | Train Shape Acc: 0.860 | Train Movement Acc: 0.716 | Test Loss: 642.7324 | Test Shape Acc: 0.388 | Test Movement Acc: 0.117\n",
      "Epoch: 49 | Train Loss: 133.1589 | Train Shape Acc: 0.870 | Train Movement Acc: 0.738 | Test Loss: 619.2873 | Test Shape Acc: 0.397 | Test Movement Acc: 0.125\n",
      "Total Training time: 2237.768 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "LR = 0.1\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "model_results = train(model,\n",
    "                        train_dataloader=trainloader,\n",
    "                        test_dataloader=testloader,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total Training time: {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/result.json\", 'w') as f:\n",
    "    json.dump(model_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './data/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
